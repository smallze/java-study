阅读[美团分布式id实现方式](https://tech.meituan.com/2017/04/21/mt-leaf.html)有感总结归纳

## ID要求

- 全局唯一
- 趋势递增，MySQL InnoDB使用B-tree数据结构来存储索引数据，使用有序的主键来保证写入性能
- 单调递增，保证下一个ID大于上一个ID，可以排序
- 信息安全，如果ID是连续的，很容易被爬取数据，有些应用场景的ID需要无规则、不规则

## 常见方法介绍

#### 自增id

- 优点：有序，检索快！占用空间小，写入效率高！
- 缺点：
  - 导入旧数据时，可能会ID重复，导致导入失败
  - 分布式架构，多个Mysql实例可能会导致ID重复。

#### UUID

- 优点：性能高，本地生成，没有网络消耗
- 缺点：
  - 长度太长，不易存储；
  - 信息不安全，基于MAC地址生成的UUID的算法，可能造成MAC地址泄露；
  - 为主键时不适合，MySQL官方要求越短越好，在InnoDB的引擎下，UUID的无序性可能会引起数据位置的频繁变动，严重影响性能

#### 类snowflake算法 待用java实现

- 优点：
  - 毫秒在高位，自增序列在低位，整个ID处于递增
  - 不依赖第三方系统，以服务的方式部署，稳定性更高，生成ID的性能非常好
  - 可以根据业务特性分配bit位，非常灵活
- 缺点：
  - 强依赖时钟，如果机器上时钟回拨，会导致重复或服务处于不可用状态

#### 数据库生成

​	利用给字段设置`auto_increment_increment`和`auto_increment_offset`来保证ID自增，每次业务使用下列SQL读写MySQL得到ID号

优点：

- 非常简单，利用现有数据库系统的功能实现，成本小，有DBA专业维护。
- ID号单调自增，可以实现一些对ID有特殊要求的业务。

缺点：

- 强依赖DB，当DB异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。
- ID发号性能瓶颈限制在单台MySQL的读写性能。

#### leaf-segment 这块还是得实践下！！！

在数据库生成的基础上做了优化：原来是每一次都访问数据库获取最新的id，造成数据库压力大，改成使用proxy server批量获取，每次获取一个segment号段的值，用完再取。

数据库表设计如下：

```sql
+-------------+--------------+------+-----+-------------------+-----------------------------+
| Field       | Type         | Null | Key | Default           | Extra                       |
+-------------+--------------+------+-----+-------------------+-----------------------------+
| biz_tag     | varchar(128) | NO   | PRI |                   |                             |
| max_id      | bigint(20)   | NO   |     | 1                 |                             |
| step        | int(11)      | NO   |     | NULL              |                             |
| desc        | varchar(256) | YES  |     | NULL              |                             |
| update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
+-------------+--------------+------+-----+-------------------+-----------------------------+
```

重要字段说明：biz_tag用来区分业务，max_id表示该biz_tag目前所被分配的ID号段的最大值，step表示每次分配的号段长度。原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000。那么只有当1000个号被消耗完了之后才会去重新读写一次数据库。读写数据库的频率从1减小到了1/step，大致架构如下图所示：

![image](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/5e4ff128.png)

test_tag在第一台Leaf机器上是1~1000的号段，当这个号段用完时，会去加载另一个长度为step=1000的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是3001~4000。同时数据库对应的biz_tag这条数据的max_id会从3000被更新成4000，更新号段的SQL语句如下：

```sql
Begin
UPDATE table SET max_id=max_id+step WHERE biz_tag=xxx
SELECT tag, max_id, step FROM table WHERE biz_tag=xxx
Commit
```

这种模式有以下优缺点：

优点：

- Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
- ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
- 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
- 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。

缺点：

- ID号码不够随机，能够泄露发号数量的信息，不太安全。
- TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，tg999数据会出现偶尔的尖刺。
- DB宕机会造成整个系统不可用。

### 双buffer优化

优化取号段的处理，在号段用到10%时，获取下一个号段，依次类推

## Leaf-snowflake方案

基于snowflake的bit位设计，保证趋势和单调递增，弱依赖zk，使用zookeeper发号



某公众号总结 https://mp.weixin.qq.com/s/iHccKiTZUOEhauAisDYyGg

总结（csdn看到的）

1.单实例，单节点，由于InnoDB的特性，自增ID效率大于UUID.

2.20个节点以下小型分布式架构：为了实现快速部署，主键不重复，可以采用UUID

3.20到200个节点：可以采用自增ID+步长的较快速方案。

4.200个以上节点的分布式架构：可以采用twitter的雪花算法全局自增ID